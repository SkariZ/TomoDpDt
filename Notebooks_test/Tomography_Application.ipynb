{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "import deeptrack as dt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_functions import estimate_rotations_from_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tomography(dl.Application):\n",
    "    def __init__(self,\n",
    "                 volume_size: Optional[Sequence(int)] = (96,96,96),\n",
    "                 vae_model: Optional[torch.nn.Module]=None,\n",
    "                 imaging_model: Optional[torch.nn.Module] = None,\n",
    "                 initial_volume: Optional[str] = None, #Or provide initial guess for volume explicitly\n",
    "                 optimizer=None,\n",
    "                 volume_init=None,\n",
    "                 **kwargs,\n",
    "\n",
    "\n",
    "\n",
    "                 ):\n",
    "        self.N=volume_size[0]\n",
    "        self.vae_model=vae_model or dl.VariationalAutoEncoder(input_size=(self.volume_size[0],self.volume_size[1]))\n",
    "        self.encoder=self.vae_model.encoder\n",
    "        self.fc_mu=self.vae_model.fc_mu\n",
    "        self.imaging_model=imaging_model or Projections\n",
    "        self.device=self.vae_model.device\n",
    "        self.initial_volume=initial_volume\n",
    "        self.volume_init = volume_init\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.optimizer = optimizer or Adam(lr=5e-3)\n",
    "    def initialize_parameters(self,projections,**kwargs):\n",
    "        latent_space = self.vae.fc_mu(self.vae.encoder(projections))\n",
    "        self.latent = latent_space\n",
    "        self.volume = self.initialize_volume()\n",
    "        self.rotation_params = estimate_rotations_from_latent(latent_space,**kwargs) #Later: add axis also\n",
    "        \n",
    "        # Setting frames to the number of quaternions\n",
    "        self.frames = projections[:len(self.quaternions)]\n",
    "        @self.optimizer.params\n",
    "        def params(self):\n",
    "            return self.parameters()\n",
    "\n",
    "    def train_vae(self, projections):\n",
    "        self.vae.fit(projections)\n",
    "        for param in self.vae.Parameters():\n",
    "            param.requires_grad=False\n",
    "        #for param in self.vae.fc_mu.Parameters():\n",
    "        #    param.requires_grad=False\n",
    "\n",
    "    def initialize_volume(self):\n",
    "        \"\"\"\n",
    "        Initialize the volume.\n",
    "\n",
    "        Returns:\n",
    "        - volume (torch.Tensor): Initialized volume.\n",
    "        \"\"\"\n",
    "        if self.initial_volume == 'gaussian':\n",
    "            x = torch.arange(self.N) - self.N / 2\n",
    "            xx, yy, zz = torch.meshgrid(x, x, x, indexing='ij')\n",
    "            cloud = torch.exp(-0.001 * (xx**2 + yy**2 + zz**2))\n",
    "            cloud = cloud / cloud.max()\n",
    "            cloud = cloud.to(self.device)\n",
    "            self.volume = nn.Parameter(cloud)\n",
    "\n",
    "        elif self.initial_volume == 'constant':\n",
    "            self.volume = nn.Parameter(torch.ones(self.N, self.N, self.N, device=self.device))\n",
    "\n",
    "        elif self.initial_volume == 'random':\n",
    "            self.volume = nn.Parameter(torch.rand(self.N, self.N, self.N, device=self.device))\n",
    "\n",
    "        elif self.initial_volume == 'given' and self.volume_init is not None:\n",
    "            self.volume = nn.Parameter(self.volume_init.to(self.device))\n",
    "\n",
    "        else:\n",
    "            self.volume = nn.Parameter(torch.zeros(self.N, self.N, self.N, device=self.device))\n",
    "    \n",
    "    def forward(self,idx):\n",
    "        volume=self.volume\n",
    "        rotations=self.get_quaternions(self.rotation_params)[idx]\n",
    "        batch_size = rotations.shape[0]\n",
    "        estimated_projections = torch.zeros(batch_size, self.N, self.N, device=self.device)\n",
    "        for i in range(batch_size):\n",
    "            rotated_volume=self.apply_rotation(volume,rotations[i])\n",
    "            estimated_projections[i]=self.imaging_model(rotated_volume)\n",
    "        return estimated_projections\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        #x,y = self.train_preprocess(batch) # batch = ground_truth projections\n",
    "\n",
    "        \n",
    "        \n",
    "        yhat=self.forward(batch_idx) #Estimated projections\n",
    "\n",
    "        latent_space = self.fc_mu(self.encoder(yhat))\n",
    "\n",
    "        proj_loss,latent_loss=self.compute_loss(yhat,latent_space,batch,batch_idx)\n",
    "        tot_loss=proj_loss+latent_loss\n",
    "        loss = {\"proj_loss\": proj_loss, \"latent_loss\": latent_loss, \"total_loss\": tot_loss}\n",
    "        for name, v in loss.items():\n",
    "            self.log(\n",
    "                f\"train_{name}\",\n",
    "                v,\n",
    "                on_step=True,\n",
    "                on_epoch=True,\n",
    "                prog_bar=True,\n",
    "                logger=True,\n",
    "            )\n",
    "        return tot_loss\n",
    "    def compute_loss(yhat,y):\n",
    "        XXX\n",
    "        return XXX\n",
    "\n",
    "    def apply_rotation(self, volume, q):\n",
    "        \"\"\"\n",
    "        Rotate the object using quaternions.\n",
    "\n",
    "        Parameters:\n",
    "        - volume (torch.Tensor): The volume to rotate.\n",
    "        - q (torch.Tensor): Quaternions representing rotations.\n",
    "\n",
    "        Returns:\n",
    "        - rotated_volume (torch.Tensor): Rotated volume.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert quaternions to rotation matrix\n",
    "        q = q / q.norm()  # Ensure unit quaternion\n",
    "        R = self.quaternion_to_rotation_matrix(q)\n",
    "        \n",
    "        # Create a rotation grid\n",
    "        grid = self.grid.view(-1, 3)\n",
    "        rotated_grid = torch.matmul(grid, R.t()).view(self.N, self.N, self.N, 3)\n",
    "        \n",
    "        # Normalize the grid values to be in the range [-1, 1] for grid_sample\n",
    "        rotated_grid = (rotated_grid / (self.N / 2)).clamp(-1, 1)\n",
    "        \n",
    "        # Apply grid_sample to rotate the volume\n",
    "        rotated_volume = F.grid_sample(volume.unsqueeze(0).unsqueeze(0), rotated_grid.unsqueeze(0), align_corners=True)\n",
    "        return rotated_volume.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "L=range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sum all values in L\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deeplay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
